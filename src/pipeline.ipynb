{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6481bb",
   "metadata": {},
   "source": [
    "# Low power person detection on UAVs\n",
    "\n",
    "This is the notebook with holds the complete pipeline for our project in TinyML!\n",
    "\n",
    "Our goal is to deploy optimized person detection models on edge devices with regards to trade-offs between power-consumption, inference speed and accuracy. \n",
    "\n",
    "We load, retrain, optimize, benchmark and deploy these models in this jupyternotebook, which is a compressed version of the source code in this repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3847296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0595225",
   "metadata": {},
   "source": [
    "## We start with loading different models \n",
    "At the start of the project we used models from EfficientDet, Fomo, Yolo and mobilenet_ssd. After comparison we decided to only move forward with the YOLO model, therefore later code is written only for the yolo architecture.\n",
    "\n",
    "For EfficientDet and Mobilenet-ssd we use tensorflow-hub to get the models, while FOMO is only available via manual download from Edge-Impulse. The usage of YOLO is greatly simplified by using the ultralytics library for YOLO, which handles download and provides a training framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a12255af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model.py\n",
    "\n",
    "def load_yolo(model_name : str, model_name_ext: str):\n",
    "    \"\"\"\n",
    "    Loads a YOLO modle\n",
    "    \"\"\"\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    model = YOLO(model_name_ext)\n",
    "    exported_path = model.export(format=\"saved_model\")\n",
    "\n",
    "\n",
    "    return exported_path\n",
    "\n",
    "\n",
    "def load_mobilenet_ssd(model_name: str, model_url: str = \"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\"):\n",
    "    \"\"\"Loads MobileNet SSD from TensorFlow Hub\"\"\"\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    \n",
    "    model = hub.load(model_url)\n",
    "    saved_model_path = f\"{model_name}_saved_model\"\n",
    "    tf.saved_model.save(model, saved_model_path)\n",
    "    return saved_model_path\n",
    "\n",
    "\n",
    "def load_efficientdet(model_name: str, model_url: str = \"https://tfhub.dev/tensorflow/efficientdet/d0/1\"):\n",
    "    \"\"\"Loads EfficientDet from TensorFlow Hub\"\"\"\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    model = hub.load(model_url)\n",
    "    saved_model_path = f\"{model_name}_saved_model\"\n",
    "    tf.saved_model.save(model, saved_model_path)\n",
    "    return saved_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f99185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.208 ðŸš€ Python-3.12.3 torch-2.8.0+cu128 CPU (AMD Ryzen 7 7735U with Radeon Graphics)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 22...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.71...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as 'yolo11n.onnx' (10.2 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n",
      "Saved artifact at 'yolo11n_saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 84, 8400), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  131192950550992: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  131193089389584: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
      "  131192950550800: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  131192950541008: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  131192950550224: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
      "  131192950549840: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131192950549648: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
      "  131193117496272: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193117495120: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117491472: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117496464: TensorSpec(shape=(3, 3, 16, 8), dtype=tf.float32, name=None)\n",
      "  131193117499152: TensorSpec(shape=(8,), dtype=tf.float32, name=None)\n",
      "  131193117495888: TensorSpec(shape=(3, 3, 8, 16), dtype=tf.float32, name=None)\n",
      "  131193117492048: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  131193117491280: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117493584: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117496848: TensorSpec(shape=(1, 1, 48, 64), dtype=tf.float32, name=None)\n",
      "  131193117499536: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193117494736: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  131193117497232: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193117497808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193117496656: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193117498576: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193117502992: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117499728: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117503184: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
      "  131193117503376: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  131193117502224: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
      "  131193117496080: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193117499920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117503952: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117502032: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n",
      "  131193117504336: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193117502800: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  131193117505104: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  131193117500688: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193117501648: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  131193117500112: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193121171280: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193121175504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193117500496: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
      "  131193117503760: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193121172048: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  131193121173968: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193121172432: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  131193121818192: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193121818384: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  131193121819152: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193121818960: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  131193117503568: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
      "  131193121817808: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193121177040: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193121830096: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193121824528: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193121171664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193121173008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193121823952: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  131193121819344: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193121827792: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  131193121822416: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
      "  131193121821840: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193121827408: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  131193121827984: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193121830864: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193121832400: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193121822224: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  131193121820304: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193121820880: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193121819728: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193121829520: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193121824720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193121828944: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193121831056: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193121829712: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193121828752: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  131193121831440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193121832208: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193121823376: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  131193121826448: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193121831248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193121832784: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193121828560: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  131193121818768: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193121832016: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  131193121818000: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193121831824: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
      "  131193121831632: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193121819536: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  131193121826064: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193121820496: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
      "  131193121827024: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193121826640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  131193121829328: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193121828176: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  131193121825296: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193121817424: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
      "  131193121828368: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193121827600: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
      "  131193121817616: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193121829904: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
      "  131193121830672: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193121818576: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
      "  131193121826832: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193087457424: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087452432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193121821648: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
      "  131193121830480: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193121823184: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  131193121830288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193087443216: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087452240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087455504: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  131193087444944: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131193087452816: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n",
      "  131193087452048: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193087444176: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087443600: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087445904: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
      "  131193087447056: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
      "  131193087450896: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
      "  131193087454736: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131193087447632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087443984: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087449936: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
      "  131193087452624: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193087444560: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  131193087443792: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193087445328: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193087446288: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  131193087447824: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131192961401104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131192961402832: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087446096: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
      "  131193087448016: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  131192961403408: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
      "  131192961402256: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192961403792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131192961403600: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131192961404752: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  131192961401680: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131192961405712: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  131192961404368: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  131192961406288: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131192961405136: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  131192961406864: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131192961408976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131192961407824: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131192961401872: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  131192961406480: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192961402448: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192971021776: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192971026576: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192971028496: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192971029840: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192971025808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192971026384: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192961407440: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
      "  131192971027728: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192961408016: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192971027344: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
      "  131192971027536: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131192961407248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131192961408784: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
      "  131193087449168: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n",
      "  131193087448592: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192971027920: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  131192971026960: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131193087446864: TensorSpec(shape=(1, 1, 64, 80), dtype=tf.float32, name=None)\n",
      "  131193087448208: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192971028112: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
      "  131192961404560: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
      "  131192971025616: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  131192961401488: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  131192971030224: TensorSpec(shape=(1, 1, 256, 80), dtype=tf.float32, name=None)\n",
      "  131192961405520: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
      "  131193087445520: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
      "  131192971030032: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192961402064: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131193087448784: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192971031376: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
      "  131192971027152: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
      "  131192961409168: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
      "  131192961405904: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
      "  131193087443408: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192971028688: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192971026768: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192961406672: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192961402640: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193087447440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193087448400: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
      "  131193087445136: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192971032144: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
      "  131192971023120: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192961407056: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
      "  131192961403984: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131193087448976: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192971029072: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192971029264: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192961403024: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192961405328: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131193087446480: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192971033488: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
      "  131192971030416: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192971024272: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
      "  131192961409360: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192961404944: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
      "  131193087449744: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
      "  131192971030800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192971030992: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192961407632: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192971026000: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131193087445712: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  131192961400912: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  131192971021968: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  131192971031760: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  131192971034256: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
      "  131192971034448: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  131192971025424: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  131192971030608: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  131192971034064: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  131192971029648: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
      "  131192971022352: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
      "  131192971033872: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
      "  131192971032720: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761037356.341521    9204 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1761037356.341645    9204 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1761037357.312253    9204 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1761037357.312278    9204 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1761037357.775859    9204 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1761037357.775983    9204 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1761037358.264533    9204 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1761037358.264560    9204 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 10.9s, saved as 'yolo11n_saved_model' (25.7 MB)\n",
      "\n",
      "Export complete (11.2s)\n",
      "Results saved to \u001b[1m/home/jakub/Documents/semester5/TinyML/uav-person/low-power-person-detection-uav-sar/src\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n_saved_model imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11n_saved_model imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# download the yolo model\n",
    "model_name = \"yolo11n\"\n",
    "model_name_ext = \"yolo11n.pt\"\n",
    "yolo_saved_model_path = load_yolo(model_name, model_name_ext)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeca6a",
   "metadata": {},
   "source": [
    "We now downloaded Yolo11n.pt and will continue by using one of two domain-specific datasets to retrain and with that finetune these models for the deployment of person-detection on UAVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdec2b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA:  False\n",
      "No GPU\n",
      "New https://pypi.org/project/ultralytics/8.3.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.208 ðŸš€ Python-3.12.3 torch-2.8.0+cu128 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: -1\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmultiprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m freeze_support\n\u001b[32m     39\u001b[39m freeze_support()  \u001b[38;5;66;03m# optional, but safe on Windows\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# export()\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     19\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolo11n.pt\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model \u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Train the model using VisDrone dataset\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# results = model.train(data=\"VisDrone.yaml\", device=0, epochs=100, imgsz=640, batch=16, plots=True)\u001b[39;00m\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# OR\u001b[39;00m\n\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Train the model using C2A dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mc2a-yolo.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplots\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/semester5/TinyML/uav-person/low-power-person-detection-uav-sar/tinyml/lib/python3.12/site-packages/ultralytics/engine/model.py:795\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.get(\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    793\u001b[39m     args[\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.ckpt_path\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer = \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrainer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args.get(\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/semester5/TinyML/uav-person/low-power-person-detection-uav-sar/tinyml/lib/python3.12/site-packages/ultralytics/models/yolo/detect/train.py:65\u001b[39m, in \u001b[36mDetectionTrainer.__init__\u001b[39m\u001b[34m(self, cfg, overrides, _callbacks)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg=DEFAULT_CFG, overrides: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, _callbacks=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     57\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m    Initialize a DetectionTrainer object for training YOLO object detection model training.\u001b[39;00m\n\u001b[32m     59\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m \u001b[33;03m        _callbacks (list, optional): List of callback functions to be executed during training.\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/semester5/TinyML/uav-person/low-power-person-detection-uav-sar/tinyml/lib/python3.12/site-packages/ultralytics/engine/trainer.py:126\u001b[39m, in \u001b[36mBaseTrainer.__init__\u001b[39m\u001b[34m(self, cfg, overrides, _callbacks)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28mself\u001b[39m.args = get_cfg(cfg, overrides)\n\u001b[32m    125\u001b[39m \u001b[38;5;28mself\u001b[39m.check_resume(overrides)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28mself\u001b[39m.device = \u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Update \"-1\" devices so post-training val does not repeat search\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;28mself\u001b[39m.args.device = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.device) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/semester5/TinyML/uav-person/low-power-person-detection-uav-sar/tinyml/lib/python3.12/site-packages/ultralytics/utils/torch_utils.py:199\u001b[39m, in \u001b[36mselect_device\u001b[39m\u001b[34m(device, newline, verbose)\u001b[39m\n\u001b[32m    192\u001b[39m         LOGGER.info(s)\n\u001b[32m    193\u001b[39m         install = (\n\u001b[32m    194\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    195\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCUDA devices are seen by torch.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.device_count() == \u001b[32m0\u001b[39m\n\u001b[32m    197\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    198\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    200\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid CUDA \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m requested.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    201\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Use \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=cpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or pass valid CUDA device(s) if available,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m i.e. \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=0\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=0,1,2,3\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for Multi-GPU.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtorch.cuda.is_available(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.is_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtorch.cuda.device_count(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.device_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mos.environ[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisible\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m         )\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.is_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[32m    210\u001b[39m     devices = device.split(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# i.e. \"0,1\" -> [\"0\", \"1\"]\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: -1\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
     ]
    }
   ],
   "source": [
    "#train.py\n",
    "\n",
    "# Sys info:\n",
    "\n",
    "\n",
    "# print(torch.__version__)\n",
    "# print(torch.version.cuda)\n",
    "\n",
    "print(\"PyTorch CUDA: \", torch.cuda.is_available())\n",
    "# print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
    "# print(\"Ultralytics CUDA: \", YOLO(\"yolo11n.pt\").device)\n",
    "\n",
    "yolo_retrained_model_path = \"some path\"\n",
    "\n",
    "\n",
    "def train():\n",
    "    # Load a model\n",
    "    model = YOLO(\"yolo11n.pt\")  # load a pretrained model \n",
    "\n",
    "\n",
    "    # Train the model using VisDrone dataset\n",
    "    # results = model.train(data=\"VisDrone.yaml\", device=0, epochs=100, imgsz=640, batch=16, plots=True)\n",
    "\n",
    "    # OR\n",
    "\n",
    "    # Train the model using C2A dataset\n",
    "    results = model.train(data=\"c2a-yolo.yaml\", device=0, epochs=100, imgsz=640, batch=16, plots=True)\n",
    "\n",
    "def export():\n",
    "    best_model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "    best_model.export(format=\"onnx\")\n",
    "    # best_model.export(format=\"tflite\", imgsz=640, half=False, int8=False)\n",
    "    # best_model.export(format=\"tflite\", imgsz=640, int8=True, data=\"VisDrone.yaml\")\n",
    "\n",
    "\n",
    "\n",
    "from multiprocessing import freeze_support\n",
    "freeze_support()  # optional, but safe on Windows\n",
    "train()\n",
    "# export()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a02fd",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "After retraining the model on our domain specific dataset, we want to optimize the model for Edge-deployment. \n",
    "\n",
    "For this, we wrote a script with some optimization methods from the lecture and some other options from tensorflow-lite.\n",
    "\n",
    "**We optimize for:**\n",
    "- Size\n",
    "- Latency\n",
    "- Trade-off (.DEFAULT)\n",
    "\n",
    "**We quantisize:**\n",
    "- f32 ( no quantization)\n",
    "- f16\n",
    "- dynamic int 8\n",
    "\n",
    "\n",
    "**With following settings:**\n",
    "- restrict to tensorflow builtin ops\n",
    "- match inference in-/output types to quanitzation types\n",
    "- Experimental Converter = true ( may support more features and improved conversion)\n",
    "- allow_custom_ops = Tru - allows custom TensorFlow operations, not neccessary but no harm either\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def optimize_model(model_name: str, model_path: str, output_dir: str = \"models/optimized_models\"):\n",
    "    \"\"\"Generate different variants of optimized models\"\"\"\n",
    "    \n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Size optimized variants \n",
    "    _convert(model_name, model_path, output_dir, \"size_float32\", tf.lite.Optimize.OPTIMIZE_FOR_SIZE, None)\n",
    "    _convert(model_name, model_path, output_dir, \"size_float16\", tf.lite.Optimize.OPTIMIZE_FOR_SIZE, tf.float16)\n",
    "    _convert(model_name, model_path, output_dir, \"size_dynamic\", tf.lite.Optimize.OPTIMIZE_FOR_SIZE, \"dynamic\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Latency optimized variants\n",
    "    _convert(model_name, model_path, output_dir, \"latency_float32\", tf.lite.Optimize.OPTIMIZE_FOR_LATENCY, None)\n",
    "    _convert(model_name, model_path, output_dir, \"latency_float16\", tf.lite.Optimize.OPTIMIZE_FOR_LATENCY, tf.float16)\n",
    "    _convert(model_name, model_path, output_dir, \"latency_dynamic\", tf.lite.Optimize.OPTIMIZE_FOR_LATENCY, \"dynamic\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _convert(model_name: str, model_path: str, output_dir: str, suffix: str, optimization, quant_type):\n",
    "    \"\"\"Helper function to convert model with specific settings\"\"\"\n",
    "\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(model_path)\n",
    "    converter.optimizations = [optimization]\n",
    "\n",
    "    # restrict to tensorflow builtin ops\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "\n",
    "    # float16 quantization\n",
    "    if quant_type == tf.float16:\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "        converter.inference_input_type = tf.float16\n",
    "        converter.inference_output_type = tf.float16\n",
    "    # try dynamic range quantization\n",
    "    elif quant_type == \"dynamic\":\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.inference_input_type = tf.float32\n",
    "        converter.inference_output_type = tf.float32\n",
    "    else:\n",
    "        converter.inference_input_type = tf.float32\n",
    "        converter.inference_output_type = tf.float32\n",
    "\n",
    "    # try with experimental converter\n",
    "    converter.experimental_new_converter = True\n",
    "\n",
    "    # custom ops (not neccessary i think)\n",
    "    converter.allow_custom_ops = True\n",
    "\n",
    "\n",
    "    try:\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "    except ValueError as e:\n",
    "\n",
    "        print(f\"Skipping {suffix} for {model_name}: {e}\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"{model_name}_{suffix}.tflite\")\n",
    "\n",
    "    with open(output_path, 'wb') as f:\n",
    "\n",
    "        f.write(tflite_model)\n",
    "\n",
    "\n",
    "    print(f\"{suffix}: {output_path} ({len(tflite_model) / (1024*1024):.2f} MB)\")\n",
    "\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b560783",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yolo_retrained_model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m optimize_model(model_name, \u001b[43myolo_retrained_model_path\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'yolo_retrained_model_path' is not defined"
     ]
    }
   ],
   "source": [
    "optimize_model(model_name, yolo_retrained_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ab7f7",
   "metadata": {},
   "source": [
    "Choosing a optimized model :( SOME MODEL )\n",
    "we can now run some inference on example pictures to see where stengths and weaknesses of our detection lie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e4ca4",
   "metadata": {},
   "source": [
    "To gain actual knowledge we run different benchmarks on our models to compare them performance and power wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e13bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchamrking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
